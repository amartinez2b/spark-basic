{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9a753ff-d25b-45b7-81ce-443b2cba5aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìò Sesi√≥n 3: Operaciones B√°sicas con DataFrames\n",
    "\n",
    "En esta sesi√≥n aprender√°s a realizar las operaciones fundamentales sobre un DataFrame de PySpark:\n",
    "\n",
    "‚úÖ Selecci√≥n de columnas  \n",
    "‚úÖ Filtrado de registros  \n",
    "‚úÖ Ordenamiento  \n",
    "‚úÖ Uso de alias para renombrar columnas  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivo del ejercicio\n",
    "\n",
    "Aplicar operaciones b√°sicas sobre una tabla existente en el cat√°logo de Hive (`samples.bakehouse.sales_customers`), la cual contiene informaci√≥n de clientes de una tienda de productos horneados.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ Esquema de la tabla `sales_customers`\n",
    "\n",
    "| Campo              | Tipo    | Descripci√≥n                           |\n",
    "|--------------------|---------|----------------------------------------|\n",
    "| customerID         | long    | ID del cliente                         |\n",
    "| first_name         | string  | Nombre                                 |\n",
    "| last_name          | string  | Apellido                               |\n",
    "| email_address      | string  | Correo electr√≥nico                     |\n",
    "| phone_number       | string  | Tel√©fono                               |\n",
    "| address            | string  | Direcci√≥n                              |\n",
    "| city               | string  | Ciudad                                 |\n",
    "| state              | string  | Estado/Provincia                       |\n",
    "| country            | string  | Pa√≠s                                   |\n",
    "| continent          | string  | Continente                             |\n",
    "| postal_zip_code    | long    | C√≥digo postal                          |\n",
    "| gender             | string  | G√©nero (M/F/Otro)                      |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Actividad pr√°ctica\n",
    "\n",
    "1. Cargar el DataFrame desde la tabla del cat√°logo.\n",
    "2. Seleccionar columnas clave como `first_name`, `last_name`, `email_address`, `country`, `gender`.\n",
    "3. Filtrar los registros donde el pa√≠s sea `United States` y el g√©nero sea `F`.\n",
    "4. Ordenar los resultados por `last_name` y luego `first_name`.\n",
    "5. Renombrar columnas usando alias para visualizaci√≥n m√°s clara.\n",
    "\n",
    "üöÄ Bonus: Mostrar cu√°ntos registros cumplen la condici√≥n con `.count()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e958680d-fed6-4bb5-9929-74b8bf70af96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Leer la tabla del metastore\n",
    "df = spark.table(\"samples.bakehouse.sales_customers\")\n",
    "\n",
    "# Vista previa de datos\n",
    "display(df.limit(3))\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "df_seleccionado = df.select(\n",
    "    col(\"first_name\").alias(\"nombre\"),\n",
    "    col(\"last_name\").alias(\"apellido\"),\n",
    "    col(\"email_address\").alias(\"email\"),\n",
    "    col(\"country\").alias(\"pais\"),\n",
    "    col(\"gender\").alias(\"genero\")\n",
    ")\n",
    "\n",
    "# Filtrar registros: mujeres de Japon\n",
    "df_filtrado = df_seleccionado.filter(\n",
    "    (col(\"pais\") == \"Japan\") & (col(\"genero\") == \"female\")\n",
    ")\n",
    "\n",
    "# Ordenar por apellido y nombre\n",
    "df_ordenado = df_filtrado.orderBy(col(\"apellido\"), col(\"nombre\"))\n",
    "\n",
    "# Mostrar resultados\n",
    "df_ordenado.show(truncate=False)\n",
    "\n",
    "# Contar cu√°ntos registros cumplen la condici√≥n\n",
    "cantidad = df_ordenado.count()\n",
    "print(f\"Total de mujeres en Japon: {cantidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5acbeb37-fd95-4aef-ba64-e8f9699e6989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß™ Ejercicio pr√°ctico ‚Äî Sesi√≥n 3: Operaciones b√°sicas con DataFrames\n",
    "\n",
    "## üóÇÔ∏è Tabla: `samples.bakehouse.sales_transactions`\n",
    "\n",
    "Este ejercicio est√° basado en una tabla real del cat√°logo Hive que contiene el historial de transacciones de una cadena de panader√≠as. A partir de esta tabla, aplicaremos transformaciones y filtros utilizando funciones b√°sicas de PySpark.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objetivos\n",
    "\n",
    "1. Aplicar **funciones sobre campos de fecha** para separar la fecha y la hora desde una columna `timestamp`.\n",
    "2. **Ofuscar el n√∫mero de tarjeta** (`cardNumber`) mostrando solo los **primeros 3 d√≠gitos** y reemplazando el resto por `X`.\n",
    "3. Filtrar las transacciones realizadas con el m√©todo de pago **\"Visa\"**.\n",
    "4. Mostrar las **3 transacciones con mayor valor (`totalPrice`) pagadas con Visa**, incluyendo informaci√≥n clave.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Esquema de la tabla `sales_transactions`\n",
    "\n",
    "| Columna         | Tipo       | Descripci√≥n                             |\n",
    "|------------------|------------|------------------------------------------|\n",
    "| transactionID    | long       | ID de la transacci√≥n                     |\n",
    "| customerID       | long       | ID del cliente                           |\n",
    "| franchiseID      | long       | ID de la franquicia                      |\n",
    "| dateTime         | timestamp  | Fecha y hora de la transacci√≥n           |\n",
    "| product          | string     | Producto adquirido                       |\n",
    "| quantity         | long       | Cantidad comprada                        |\n",
    "| unitPrice        | long       | Precio unitario                          |\n",
    "| totalPrice       | long       | Precio total                             |\n",
    "| paymentMethod    | string     | M√©todo de pago (ej. Visa, Cash, etc.)    |\n",
    "| cardNumber       | long       | N√∫mero de tarjeta de cr√©dito/d√©bito      |\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Instrucciones\n",
    "\n",
    "1. Leer la tabla desde el cat√°logo de Hive usando `spark.table(...)`.\n",
    "2. Crear nuevas columnas:\n",
    "   - `fecha`: a partir de `dateTime` usando `to_date(...)`\n",
    "   - `hora`: a partir de `dateTime` usando `date_format(...)`\n",
    "3. Crear una nueva columna llamada `cardMasked` que:\n",
    "   - Muestre solo los **primeros 3 d√≠gitos** de `cardNumber`.\n",
    "   - Reemplace el resto con `\"XXXXXXXXXXXX\"` para ocultar la informaci√≥n sensible.\n",
    "4. Filtrar el DataFrame para quedarte **solo con registros donde `paymentMethod` sea \"Visa\"**.\n",
    "5. Ordenar las transacciones por `totalPrice` de mayor a menor.\n",
    "6. Mostrar solo las **3 transacciones de mayor valor**, mostrando las siguientes columnas:\n",
    "   - `transactionID`, `fecha`, `hora`, `product`, `quantity`, `totalPrice`, `paymentMethod`, `cardMasked`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Resultado esperado\n",
    "\n",
    "Una tabla final con 3 filas que contengan solo transacciones Visa, ordenadas por monto total de compra, con fecha y hora separadas y tarjeta ofuscada.\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Bonus (opcional)\n",
    "\n",
    "- Agrupar por `fecha` y calcular el total vendido por d√≠a con Visa.\n",
    "- Contar cu√°ntas transacciones Visa se realizaron por ciudad o pa√≠s si se integra con la tabla de clientes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b00a4ef1-0221-4851-83ec-3aab7fe0bd82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Escribe aqui tu codigo"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Basic_Operations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
